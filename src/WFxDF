import numpy as np
import pandas as pd
from scipy import spatial
import math
import time
import matplotlib.pyplot as plt
import random
import csv
from pathlib import Path
import os, sys
parentdir = Path(__file__).parents[1]
sys.path.append(parentdir)

def loadVector(vectorFile):
    pass

def loadDiscourseDF(corporaDir):
    # use corporaDirName to get file name to load .json file
    pass

def selectTwoCorpora(listOfUsedPairs):
    pass

def runFile(listOfUsedPairs, corporaDir, vectorDiscourses, vectorWords):
    #create system that keeps track of if a pair is already used
    selectTwoCorpora(listOfUsedPairs)
    #Calc disc frequencies, and word frequencies

def main(corporaDir, vectorDiscoursesFile, vectorWordsFile):

    vectorWords = loadVector(vectorWordsFile)
    vectorDiscourses = loadVector(vectorDiscoursesFile)
    listOfUsedPairs = set()

    jsonObj = loadDiscourseDF(corporaDir)
    for file in jsonObj:
        results = runFile(listOfUsedPairs, corporaDir, vectorDiscourses, vectorWords)
        # make listOfUsedPairs = that part of the result that was returned
    
    #create df x wf file
    with open("./results/wf_df.csv", "wt", newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["df similarity", "wf similarity"])
    
















    #for each row, select a random other row (get both corpora)
    for index, row in dfDataFrame.iterrows():
        if (index%10 == 0):
                print("running file " + str(index) + " " + str(dfDataFrame['corpus'][index]) + ": ")
                print("--- %s seconds ---" % (time.time() - start_time))
        tmp = -1
        while (tmp == -1) or (tmp == index):
            tmp = random.randint(0, l-1)

        # Calculate discourse frequencies
        vector1 = dfDataFrame['discourse vector'][index].split(' ')
        vector2 = dfDataFrame['discourse vector'][tmp].split(' ')
        for i in range(0, len(vector1)):
            vector1[i] = int(vector1[i])
            vector2[i] = int(vector2[i])
        dfVC = 1-spatial.distance.cosine(vector1, vector2) #discourse frequency vector cosine

        #Calculate word frequencies
        user1 = dfDataFrame['corpus'][index]
        user2 = dfDataFrame['corpus'][tmp]

        wfDataFrame1 = pd.read_csv("/Volumes/Robbie_External_Hard_Drive/5200_corpora_clean/" + user1 + ".csv", header=None)
        wfDataFrame1.columns = ["time", "subreddit", "wc", "comment"]
        wfDataFrame2 = pd.read_csv("/Volumes/Robbie_External_Hard_Drive/5200_corpora_clean/" + user2 + ".csv", header=None)
        wfDataFrame2.columns = ["time", "subreddit", "wc", "comment"]

        with open("./helperFiles/vector_words_150000_derived_5200_corpora.txt", "rt") as f:
            fin = f.read()
            train_words = fin.split()
            f.close

        zeros = [0]*150000 # size of WF vector
        dictionary1 = dict(zip(train_words, zeros))
        dictionary2 = dict(zip(train_words, zeros)) 

        # Perhaps randomly sample?
        wordData1 = (wfDataFrame1['comment'].str.cat(sep=' ').split())
        wordData2 = (wfDataFrame2['comment'].str.cat(sep=' ').split())

        
        for word in wordData1:
            dictionary1[word] += 1
        for word in wordData2:
            dictionary2[word] += 1
        
        # x = pd.DataFrame({'vector1': dictionary1.values(), 'vector2': dictionary2.values()})
    
        wordVector1 = list(dictionary1.values())
        wordVector2 = list(dictionary2.values())

        wfVC = 1-spatial.distance.cosine(wordVector1, wordVector2) #word frequency vector cosine

        with open("./results/wf_df.csv", "a", newline='') as f:
            writer = csv.writer(f)
            writer.writerow([dfVC, wfVC])

if __name__ == "__main__":

    start_time = time.time()
    print("Running model: WFxDF.py")

    # # Parse arguments from command line
    # parser = argparse.ArgumentParser()
    # parser.add_argument('-c', '--corpora_directory') #expects cleaned corpora 
    # parser.add_argument('-vd', '--vector_discourses_file') 
    # parser.add_argument('-vw', '--vector_words_file') 
    # args = parser.parse_args()
    # corporaDir = args.corpora_directory
    # vectorDiscoursesFile = args.vector_discourses_file
    # vectorWordsFile = args.vector_words_file

    corporaDir = os.path.join(parentdir, "data", "corpora", "50_corpora_clean")
    vectorDiscoursesFile = os.path.join(parentdir, "data", "vector_discourses_50_corpora_clean.txt")
    vectorWordsFile = os.path.join(parentdir, "data", "vector_words_50_corpora_clean.txt")
    
    main(corporaDir, vectorDiscoursesFile, vectorWordsFile)